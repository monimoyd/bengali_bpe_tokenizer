{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21UlPgg8aUWw",
        "outputId": "1bf56504-54f6-481c-df75-984de7c00f75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvI5HSBv91KH",
        "outputId": "b69fe4df-363e-4671-b03f-a307c22a32f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum num_merges :  4865\n",
            " Number of merges: 0 \n",
            " Number of merges: 100 \n",
            " Number of merges: 200 \n",
            " Number of merges: 300 \n",
            " Number of merges: 400 \n",
            " Number of merges: 500 \n",
            " Number of merges: 600 \n",
            " Number of merges: 700 \n",
            " Number of merges: 800 \n",
            " Number of merges: 900 \n",
            " Number of merges: 1000 \n",
            " Number of merges: 1100 \n",
            " Number of merges: 1200 \n",
            " Number of merges: 1300 \n",
            " Number of merges: 1400 \n",
            " Number of merges: 1500 \n",
            " Number of merges: 1600 \n",
            " Number of merges: 1700 \n",
            " Number of merges: 1800 \n",
            " Number of merges: 1900 \n",
            " Number of merges: 2000 \n",
            " Number of merges: 2100 \n",
            " Number of merges: 2200 \n",
            " Number of merges: 2300 \n",
            " Number of merges: 2400 \n",
            " Number of merges: 2500 \n",
            " Number of merges: 2600 \n",
            " Number of merges: 2700 \n",
            " Number of merges: 2800 \n",
            " Number of merges: 2900 \n",
            " Number of merges: 3000 \n",
            " Number of merges: 3100 \n",
            " Number of merges: 3200 \n",
            " Number of merges: 3300 \n",
            " Number of merges: 3400 \n",
            " Number of merges: 3500 \n",
            " Number of merges: 3600 \n",
            " Number of merges: 3700 \n",
            " Number of merges: 3800 \n",
            " Number of merges: 3900 \n",
            " Number of merges: 4000 \n",
            " Number of merges: 4100 \n",
            " Number of merges: 4200 \n",
            " Number of merges: 4300 \n",
            " Number of merges: 4400 \n",
            " Number of merges: 4500 \n",
            " Number of merges: 4600 \n",
            " Number of merges: 4700 \n",
            " Number of merges: 4800 \n",
            "Time taken to train: 15928.174258708954 seconds\n"
          ]
        }
      ],
      "source": [
        "from bengali_bpe_tokenizer import BengaliBPETokenizer\n",
        "import time\n",
        "\n",
        "def load_bengali_texts(file_paths):\n",
        "    texts = []\n",
        "    for path in file_paths:\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            texts.append(f.read())\n",
        "    return texts\n",
        "\n",
        "# Training\n",
        "data_files = [\n",
        "    \"essay.txt\",\n",
        "]\n",
        "\n",
        "# Create and train tokenizer\n",
        "tokenizer = BengaliBPETokenizer(vocab_size=5000)\n",
        "texts = load_bengali_texts(data_files)\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "tokenizer.train(texts, min_freq=2)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to train: {end_time - start_time} seconds\")\n",
        "\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save(\"bengali_bpe_tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paLAWM2DQHty",
        "outputId": "6b6dd6c1-1f26-40dd-e1f5-5bd98cbeea30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary size: 5000\n",
            "Number of merges: 4865\n"
          ]
        }
      ],
      "source": [
        "# Print some statistics\n",
        "print(f\"\\nVocabulary size: {len(tokenizer.vocab)}\")\n",
        "print(f\"Number of merges: {len(tokenizer.merges)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZQUgGTaOFAh",
        "outputId": "d04cd519-5a65-4065-fb80-172581e9137e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: হাতে তার লম্বা পাকাবাঁশের লাঠি\n",
            "Encoded: [4512, 3757, 1301, 2736, 1760, 3383, 4542, 4348, 2737, 3685]\n",
            "Decoded: হাতে তার লম্বা পাকাবাঁশের লাঠি\n",
            "Compression ratio: 3.00\n"
          ]
        }
      ],
      "source": [
        "# Test the tokenizer\n",
        "test_text = \"হাতে তার লম্বা পাকাবাঁশের লাঠি\"\n",
        "encoded = tokenizer.encode(test_text)\n",
        "decoded = tokenizer.decode(encoded)\n",
        "\n",
        "# Calculate compression ratio\n",
        "compression_ratio = tokenizer.calculate_compression_ratio(test_text)\n",
        "\n",
        "print(f\"Original text: {test_text}\")\n",
        "print(f\"Encoded: {encoded}\")\n",
        "print(f\"Decoded: {decoded}\")\n",
        "print(f\"Compression ratio: {compression_ratio:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LJQoWO6V9xH_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V56Mp6rHksdQ"
      },
      "outputs": [],
      "source": [
        "! cp bengali_bpe_tokenizer.json '/content/drive/MyDrive'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}